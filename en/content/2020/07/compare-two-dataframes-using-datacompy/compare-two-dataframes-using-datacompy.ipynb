{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Ben Du\n",
    "- Date: 2020-07-11 21:25:43\n",
    "- Modified: 2021-09-10 15:24:15\n",
    "- Title: Compare Data Frames Using DataCompy in Python\n",
    "- Slug: compare-two-dataframes-using-datacompy\n",
    "- Category: Computer Science\n",
    "- Tags: Computer Science, DataCompy, data, comparison, compare, big data, Spark, Python, DataFrame, pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "1. [data-diff](https://github.com/datafold/data-diff)\n",
    "    is similar tool \n",
    "    which efficiently diff rows across two different databases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datacompy in /home/dclong/.local/lib/python3.8/site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy<=1.22.3,>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from datacompy) (1.21.6)\n",
      "Requirement already satisfied: ordered-set<=4.1.0,>=4.0.2 in /home/dclong/.local/lib/python3.8/site-packages (from datacompy) (4.1.0)\n",
      "Requirement already satisfied: pandas<=1.4.2,>=0.25.0 in /usr/local/lib/python3.8/dist-packages (from datacompy) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas<=1.4.2,>=0.25.0->datacompy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<=1.4.2,>=0.25.0->datacompy) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas<=1.4.2,>=0.25.0->datacompy) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U datacompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/01 13:50:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import findspark\n",
    "findspark.init(str(next(Path(\"/opt\").glob(\"spark-3*\"))))\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, ArrayType\n",
    "import datacompy\n",
    "\n",
    "spark = SparkSession.builder.appName(\"datacompy\") \\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Two pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "data1 = \"\"\"acct_id,dollar_amt,name,float_fld,date_fld\n",
    "10000001234,123.45,George Maharis,14530.1555,2017-01-01\n",
    "10000001235,0.45,Michael Bluth,1,2017-01-01\n",
    "10000001236,1345,George Bluth,,2017-01-01\n",
    "10000001237,123456,Bob Loblaw,345.12,2017-01-01\n",
    "10000001238,1.05,Lucille Bluth,,2017-01-01\n",
    "10000001238,1.05,Loose Seal Bluth,,2017-01-01\n",
    "\"\"\"\n",
    "\n",
    "data2 = \"\"\"acct_id,dollar_amt,name,float_fld\n",
    "10000001234,123.4,George Michael Bluth,14530.155\n",
    "10000001235,0.45,Michael Bluth,\n",
    "10000001236,1345,George Bluth,1\n",
    "10000001237,123456,Robert Loblaw,345.12\n",
    "10000001238,1.05,Loose Seal Bluth,111\n",
    "\"\"\"\n",
    "\n",
    "df1 = pd.read_csv(StringIO(data1))\n",
    "df2 = pd.read_csv(StringIO(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acct_id</th>\n",
       "      <th>dollar_amt</th>\n",
       "      <th>name</th>\n",
       "      <th>float_fld</th>\n",
       "      <th>date_fld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001234</td>\n",
       "      <td>123.45</td>\n",
       "      <td>George Maharis</td>\n",
       "      <td>14530.1555</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000001235</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Michael Bluth</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000001236</td>\n",
       "      <td>1345.00</td>\n",
       "      <td>George Bluth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000001237</td>\n",
       "      <td>123456.00</td>\n",
       "      <td>Bob Loblaw</td>\n",
       "      <td>345.1200</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000001238</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Lucille Bluth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000001238</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Loose Seal Bluth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acct_id  dollar_amt              name   float_fld    date_fld\n",
       "0  10000001234      123.45    George Maharis  14530.1555  2017-01-01\n",
       "1  10000001235        0.45     Michael Bluth      1.0000  2017-01-01\n",
       "2  10000001236     1345.00      George Bluth         NaN  2017-01-01\n",
       "3  10000001237   123456.00        Bob Loblaw    345.1200  2017-01-01\n",
       "4  10000001238        1.05     Lucille Bluth         NaN  2017-01-01\n",
       "5  10000001238        1.05  Loose Seal Bluth         NaN  2017-01-01"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acct_id</th>\n",
       "      <th>dollar_amt</th>\n",
       "      <th>name</th>\n",
       "      <th>float_fld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001234</td>\n",
       "      <td>123.40</td>\n",
       "      <td>George Michael Bluth</td>\n",
       "      <td>14530.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000001235</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Michael Bluth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000001236</td>\n",
       "      <td>1345.00</td>\n",
       "      <td>George Bluth</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000001237</td>\n",
       "      <td>123456.00</td>\n",
       "      <td>Robert Loblaw</td>\n",
       "      <td>345.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000001238</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Loose Seal Bluth</td>\n",
       "      <td>111.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acct_id  dollar_amt                  name  float_fld\n",
       "0  10000001234      123.40  George Michael Bluth  14530.155\n",
       "1  10000001235        0.45         Michael Bluth        NaN\n",
       "2  10000001236     1345.00          George Bluth      1.000\n",
       "3  10000001237   123456.00         Robert Loblaw    345.120\n",
       "4  10000001238        1.05      Loose Seal Bluth    111.000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataComPy Comparison\n",
      "--------------------\n",
      "\n",
      "DataFrame Summary\n",
      "-----------------\n",
      "\n",
      "  DataFrame  Columns  Rows\n",
      "0  original        5     6\n",
      "1       new        4     5\n",
      "\n",
      "Column Summary\n",
      "--------------\n",
      "\n",
      "Number of columns in common: 4\n",
      "Number of columns in original but not in new: 1\n",
      "Number of columns in new but not in original: 0\n",
      "\n",
      "Row Summary\n",
      "-----------\n",
      "\n",
      "Matched on: acct_id\n",
      "Any duplicates on match values: Yes\n",
      "Absolute Tolerance: 0.0001\n",
      "Relative Tolerance: 0\n",
      "Number of rows in common: 5\n",
      "Number of rows in original but not in new: 1\n",
      "Number of rows in new but not in original: 0\n",
      "\n",
      "Number of rows with some compared columns unequal: 5\n",
      "Number of rows with all compared columns equal: 0\n",
      "\n",
      "Column Comparison\n",
      "-----------------\n",
      "\n",
      "Number of columns compared with some values unequal: 3\n",
      "Number of columns compared with all values equal: 1\n",
      "Total number of values which compare unequal: 8\n",
      "\n",
      "Columns with Unequal Values or Types\n",
      "------------------------------------\n",
      "\n",
      "       Column original dtype new dtype  # Unequal  Max Diff  # Null Diff\n",
      "0  dollar_amt        float64   float64          1    0.0500            0\n",
      "2   float_fld        float64   float64          4    0.0005            3\n",
      "1        name         object    object          3    0.0000            0\n",
      "\n",
      "Sample Rows with Unequal Values\n",
      "-------------------------------\n",
      "\n",
      "       acct_id  dollar_amt (original)  dollar_amt (new)\n",
      "0  10000001234                 123.45             123.4\n",
      "\n",
      "       acct_id name (original)            name (new)\n",
      "4  10000001238   Lucille Bluth      Loose Seal Bluth\n",
      "0  10000001234  George Maharis  George Michael Bluth\n",
      "3  10000001237      Bob Loblaw         Robert Loblaw\n",
      "\n",
      "       acct_id  float_fld (original)  float_fld (new)\n",
      "1  10000001235                1.0000              NaN\n",
      "4  10000001238                   NaN          111.000\n",
      "0  10000001234            14530.1555        14530.155\n",
      "2  10000001236                   NaN            1.000\n",
      "\n",
      "Sample Rows Only in original (First 10 Columns)\n",
      "-----------------------------------------------\n",
      "\n",
      "       acct_id  dollar_amt              name  float_fld    date_fld\n",
      "5  10000001238        1.05  Loose Seal Bluth        NaN  2017-01-01\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare = datacompy.Compare(\n",
    "    df1,\n",
    "    df2,\n",
    "    join_columns='acct_id',  #You can also specify a list of columns\n",
    "    abs_tol=0.0001,\n",
    "    rel_tol=0,\n",
    "    df1_name='original',\n",
    "    df2_name='new'\n",
    ")\n",
    "print(compare.report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Two Spark DataFrames\n",
    "\n",
    "1. There is \n",
    "    <span style=\"color:red;\">\n",
    "    no advantage of running datacompy in a local version of Spark\n",
    "    </span>!\n",
    "    This approach consumes more memory than running datacompy on pandas DataFrames\n",
    "    and costs more time.\n",
    "    \n",
    "2. If you use datacompy with a local version of Spark,\n",
    "    make sure to \n",
    "    <span style=\"color:red;\">\n",
    "    import datacompy \n",
    "    after `findspark.init(...)`\n",
    "    </span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------------+----------+----------+\n",
      "|    acct_id|dollar_amt|            name| float_fld|  date_fld|\n",
      "+-----------+----------+----------------+----------+----------+\n",
      "|10000001234|    123.45|  George Maharis|14530.1555|2017-01-01|\n",
      "|10000001235|      0.45|   Michael Bluth|       1.0|2017-01-01|\n",
      "|10000001236|    1345.0|    George Bluth|       NaN|2017-01-01|\n",
      "|10000001237|  123456.0|      Bob Loblaw|    345.12|2017-01-01|\n",
      "|10000001238|      1.05|   Lucille Bluth|       NaN|2017-01-01|\n",
      "|10000001238|      1.05|Loose Seal Bluth|       NaN|2017-01-01|\n",
      "+-----------+----------+----------------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf1 = spark.createDataFrame(df1)\n",
    "sdf1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+---------+\n",
      "|    acct_id|dollar_amt|                name|float_fld|\n",
      "+-----------+----------+--------------------+---------+\n",
      "|10000001234|     123.4|George Michael Bluth|14530.155|\n",
      "|10000001235|      0.45|       Michael Bluth|      NaN|\n",
      "|10000001236|    1345.0|        George Bluth|      1.0|\n",
      "|10000001237|  123456.0|       Robert Loblaw|   345.12|\n",
      "|10000001238|      1.05|    Loose Seal Bluth|    111.0|\n",
      "+-----------+----------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf2 = spark.createDataFrame(df2)\n",
    "sdf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = datacompy.SparkCompare(\n",
    "    spark,\n",
    "    sdf1,\n",
    "    sdf2,\n",
    "    join_columns=[\"acct_id\"],  # must use a list of column(s)\n",
    "    cache_intermediates=True,\n",
    "    abs_tol=0.0001,\n",
    "    rel_tol=0,\n",
    "    match_rates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datacompy.sparkcompare.SparkCompare"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Column Summary ******\n",
      "Number of columns in common with matching schemas: 4\n",
      "Number of columns in common with schema differences: 0\n",
      "Number of columns in base but not compare: 1\n",
      "Number of columns in compare but not base: 0\n",
      "\n",
      "****** Columns In Base Only ******\n",
      "Column Name  Dtype\n",
      "-----------  -------------\n",
      "date_fld     string       \n",
      "\n",
      "****** Row Summary ******\n",
      "Number of rows in common: 5\n",
      "Number of rows in base but not compare: 0\n",
      "Number of rows in compare but not base: 0\n",
      "Number of duplicate rows found in base: 1\n",
      "Number of duplicate rows found in compare: 0\n",
      "\n",
      "****** Row Comparison ******\n",
      "Number of rows with some columns unequal: 4\n",
      "Number of rows with all columns equal: 1\n",
      "\n",
      "****** Column Comparison ******\n",
      "Number of columns compared with some values unequal: 3\n",
      "Number of columns compared with all values equal: 0\n",
      "\n",
      "****** Columns with Unequal Values ******\n",
      "Base Column Name  Compare Column Name  Base Dtype     Compare Dtype  # Matches  # Mismatches  Match Rate %\n",
      "----------------  -------------------  -------------  -------------  ---------  ------------  ------------\n",
      "dollar_amt        dollar_amt           double         double                 4             1      80.00000\n",
      "float_fld         float_fld            double         double                 3             2      60.00000\n",
      "name              name                 string         string                 2             3      40.00000\n"
     ]
    }
   ],
   "source": [
    "comparison.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SparkCompare.report` takes a file handle to write the report to.\n",
    "You can pass a StringIO object to `SparkCompare.report` \n",
    "to write the report to a string buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with StringIO() as sio:\n",
    "    comparison.report(sio)\n",
    "    report = sio.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n****** Column Summary ******\\nNumber of columns in common with matching schemas: 4\\nNumber of columns in common with schema differences: 0\\nNumber of columns in base but not compare: 1\\nNumber of columns in compare but not base: 0\\n\\n****** Columns In Base Only ******\\nColumn Name  Dtype\\n-----------  -------------\\ndate_fld     string       \\n\\n****** Row Summary ******\\nNumber of rows in common: 5\\nNumber of rows in base but not compare: 0\\nNumber of rows in compare but not base: 0\\nNumber of duplicate rows found in base: 1\\nNumber of duplicate rows found in compare: 0\\n\\n****** Row Comparison ******\\nNumber of rows with some columns unequal: 4\\nNumber of rows with all columns equal: 1\\n\\n****** Column Comparison ******\\nNumber of columns compared with some values unequal: 3\\nNumber of columns compared with all values equal: 0\\n\\n****** Columns with Unequal Values ******\\nBase Column Name  Compare Column Name  Base Dtype     Compare Dtype  # Matches  # Mismatches  Match Rate %\\n----------------  -------------------  -------------  -------------  ---------  ------------  ------------\\ndollar_amt        dollar_amt           double         double                 4             1      80.00000\\nfloat_fld         float_fld            double         double                 3             2      60.00000\\nname              name                 string         string                 2             3      40.00000\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/capitalone/datacompy\n",
    "\n",
    "https://capitalone.github.io/datacompy/pandas_usage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
