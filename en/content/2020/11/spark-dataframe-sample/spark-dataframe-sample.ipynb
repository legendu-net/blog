{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Ben Du\n",
    "- Date: 2020-11-05 00:13:37\n",
    "- Title: Sample Rows from a Spark DataFrame\n",
    "- Slug: spark-dataframe-sample\n",
    "- Category: Computer Science\n",
    "- Tags: programming, Scala, Spark, DataFrame, sample, TABLESAMPLE\n",
    "- Modified: 2020-11-05 00:13:37\n"
   ]
  },
  {
   "source": [
    "## Tips and Traps\n",
    "\n",
    "1. `TABLESAMPLE` must be immedidately after a table name.\n",
    "\n",
    "2. The `WHERE` clause in the following SQL query runs after `TABLESAMPLE`.\n",
    "\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            table_name \n",
    "        TABLESAMPLE (10 PERCENT) \n",
    "        WHERE \n",
    "            id = 1\n",
    "\n",
    "    If you want to run a `WHERE` clause first and then do `TABLESAMPLE`,\n",
    "    you have to a subquery instead. \n",
    "\n",
    "        SELECT \n",
    "            *\n",
    "        FROM (\n",
    "            SELECT * FROM table_name\n",
    "            WHERE id = 1\n",
    "        ) A\n",
    "        TABLESAMPLE (10 PERCENT)\n",
    "\n",
    "3. Avoid using `TABLESAMPLE (k rows)` as it is not simple random sample \n",
    "    but instead implemented using `LIMIT`. \n",
    "    Always use `TABLESAMPLE (p PERCENT)` if randomness is important."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL API\n",
    "\n",
    "```\n",
    "SELECT * FROM some_table\n",
    "TABLESAMPLE (100 ROWS)\n",
    "```\n",
    "\n",
    "```\n",
    "SELECT * FROM some_table\n",
    "TABLESAMPLE (50 PERCENT)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val df = spark.read.json(\"../data/people.json\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample with Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(true, 0.9).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample without Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(false, 0.9).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|  name|\n",
      "+---+------+\n",
      "| 30|  Andy|\n",
      "| 19|Justin|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(false, 0.5).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Be Careful with Subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't persist the data frame, \n",
    "it's recalculated every time!\n",
    "This is really dangerous for any random associated data processing,\n",
    "e.g., subsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [x: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[x: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = Range(1, 100).toDF(\"x\").sample(false, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 0) / 8]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  x|\n",
      "+---+\n",
      "|  4|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 16|\n",
      "| 17|\n",
      "| 20|\n",
      "| 21|\n",
      "| 22|\n",
      "| 27|\n",
      "| 28|\n",
      "| 31|\n",
      "| 34|\n",
      "| 35|\n",
      "| 39|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do NOT Sampling a Specific Number of Rows\n",
    "\n",
    "Sampling a specific number of rows in Spark does not performance a simple random sampling,\n",
    "it is implemented as `LIMIT`\n",
    "It is suggested that you always sample a fraction instead of sampling a specific number of rows in Spark \n",
    "if randomness is important. \n",
    "\n",
    "    # avoid \n",
    "    select * from table_name TABLESAMPLE (100 ROWS) \n",
    "    # use the following instead\n",
    "    select * from table_name TABLESAMPLE (1 PCT) \n",
    "\n",
    "## References\n",
    "\n",
    "https://stackoverflow.com/questions/51502443/is-sample-n-really-a-random-sample-when-used-with-sparklyr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}