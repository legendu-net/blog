{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: Read/Write TSV in Spark\n",
    "- Slug: spark-io-tsv\n",
    "- Date: 2019-11-26\n",
    "- Category: Computer Science\n",
    "- Tags: programming, Scala, Spark, TSV, text\n",
    "- Author: Ben Du\n",
    "- Modified: 2019-11-26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54471567-a823-4f3b-b94e-7c7427578a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.apache.spark spark-core_2.11 2.3.1\n",
    "org.apache.spark spark-sql_2.11 2.3.1\n",
    "org.apache.spark spark-hive_2.11 2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data in TSV Format\n",
    "\n",
    "1. `.load` is a general method for reading data in different format. \n",
    "    You have to specify the format of the data via the method `.format` of course.\n",
    "    `.csv` (both for CSV and TSV), `.json` and `.parquet` are specializations of `.load`. \n",
    "    `.format` is optional if you use a specific loading function (csv, json, etc.).\n",
    "\n",
    "2. No header by default.\n",
    "\n",
    "3. `.coalesece(1)` or `repartition(1)` if you want to write to only 1 file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data in TSV Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bf026d-6d5f-49d7-b330-a2ad0355fe58",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.apache.spark spark-core_2.11 2.1.1\n",
    "org.apache.spark spark-sql_2.11 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@4549fbd9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    "    .builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"spark load tsv\")\n",
    "    .config(\"spark-config-some-option\", \"some-value\")\n",
    "    .getOrCreate()\n",
    "// spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+---------+-------+-------+------+------+----+--------+--------+----+---+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|cancelled|carrier|tailnum|flight|origin|dest|air_time|distance|hour|min|\n",
      "+----+-----+---+--------+---------+--------+---------+---------+-------+-------+------+------+----+--------+--------+----+---+\n",
      "|2014|    6| 13|    1724|      114|    2125|      158|        0|     B6| N709JB|  1729|   JFK| RSW|     154|    1074|  17| 24|\n",
      "|2014|    6| 13|    1942|      223|    2211|      282|        0|     B6| N304JB|  1734|   JFK| BTV|      49|     266|  19| 42|\n",
      "|2014|    6| 13|    1345|        4|    1641|       11|        0|     B6| N796JB|  1783|   JFK| MCO|     137|     944|  13| 45|\n",
      "|2014|    6| 13|    1552|        0|    1916|        8|        0|     B6| N184JB|  1801|   JFK| FLL|     166|    1069|  15| 52|\n",
      "|2014|    6| 13|     119|      151|     215|      137|        0|     B6| N203JB|  1816|   JFK| SYR|      41|     209|   1| 19|\n",
      "+----+-----+---+--------+---------+--------+---------+---------+-------+-------+------+------+----+--------+--------+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val flights = spark.read.\n",
    "    format(\"csv\").\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"delimiter\", \"\\t\").\n",
    "    option(\"mode\", \"DROPMALFORMED\").\n",
    "    csv(\"f2.tsv\")\n",
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+---------+-------+-------+------+------+----+--------+--------+----+---+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|cancelled|carrier|tailnum|flight|origin|dest|air_time|distance|hour|min|\n",
      "+----+-----+---+--------+---------+--------+---------+---------+-------+-------+------+------+----+--------+--------+----+---+\n",
      "|2014|    3| 27|     538|       -7|     824|      -21|        0|     AA| N640AA|  2243|   JFK| MIA|     147|    1089|   5| 38|\n",
      "|2014|    3| 27|     812|       -8|    1113|      -22|        0|     AA| N3GLAA|  2267|   LGA| MIA|     151|    1096|   8| 12|\n",
      "|2014|    3| 27|     952|       -7|    1310|        1|        0|     AA| N3KGAA|  2335|   LGA| MIA|     153|    1096|   9| 52|\n",
      "|2014|    3| 27|    1506|       -4|    1810|      -15|        0|     AA| N3CWAA|  1327|   LGA| PBI|     148|    1035|  15|  6|\n",
      "|2014|    3| 27|     704|       -6|    1013|       -7|        0|     AA| N3GHAA|  2279|   LGA| MIA|     151|    1096|   7|  4|\n",
      "+----+-----+---+--------+---------+--------+---------+---------+-------+-------+------+------+----+--------+--------+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val flights = spark.read.\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"delimiter\", \"\\t\").\n",
    "    csv(\"f2.tsv\")\n",
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+---------+-------+-------+------+------+----+--------+--------+----+----+\n",
      "| _c0|  _c1|_c2|     _c3|      _c4|     _c5|      _c6|      _c7|    _c8|    _c9|  _c10|  _c11|_c12|    _c13|    _c14|_c15|_c16|\n",
      "+----+-----+---+--------+---------+--------+---------+---------+-------+-------+------+------+----+--------+--------+----+----+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|cancelled|carrier|tailnum|flight|origin|dest|air_time|distance|hour| min|\n",
      "|2014|    3| 27|     538|       -7|     824|      -21|        0|     AA| N640AA|  2243|   JFK| MIA|     147|    1089|   5|  38|\n",
      "|2014|    3| 27|     812|       -8|    1113|      -22|        0|     AA| N3GLAA|  2267|   LGA| MIA|     151|    1096|   8|  12|\n",
      "|2014|    3| 27|     952|       -7|    1310|        1|        0|     AA| N3KGAA|  2335|   LGA| MIA|     153|    1096|   9|  52|\n",
      "|2014|    3| 27|    1506|       -4|    1810|      -15|        0|     AA| N3CWAA|  1327|   LGA| PBI|     148|    1035|  15|   6|\n",
      "+----+-----+---+--------+---------+--------+---------+---------+-------+-------+------+------+----+--------+--------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val flights = spark.read.\n",
    "    option(\"delimiter\", \"\\t\").\n",
    "    csv(\"f2.tsv\")\n",
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write DataFrame to TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val flights = spark.read.\n",
    "    format(\"csv\").\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"mode\", \"DROPMALFORMED\").\n",
    "    csv(\"flights14.csv\")\n",
    "flights.write.\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"delimiter\", \"\\t\").\n",
    "    csv(\"f2.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/Dataset.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/functions.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/Row.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}