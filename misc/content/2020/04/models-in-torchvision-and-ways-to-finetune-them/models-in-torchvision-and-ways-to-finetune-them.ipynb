{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Author: Ben Du\n",
    "- Date: 2020-04-21 13:26:15\n",
    "- Title: Models in Torchvision and Ways to Finetune Them\n",
    "- Slug: models-in-torchvision-and-ways-to-finetune-them\n",
    "- Category: Computer Science\n",
    "- Tags: Computer Science, data science, AI, machine learning, deep learning, PyTorch, models, torchvision\n",
    "- Modified: 2020-04-21 13:26:15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3 requires an input of (299, 299)\n",
    "while other models requires an input of (224, 224).\n",
    "Due to adaptive pooling used in some of the models, \n",
    "some of the models can handle varying sized input. \n",
    "However, \n",
    "it is suggested that you still resize/crop the input to be the best input size before feeding them to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[TORCHVISION.MODELS](https://pytorch.org/docs/stable/torchvision/models.html)\n",
    "\n",
    "[FINETUNING TORCHVISION MODELS](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)\n",
    "\n",
    "[Torchvision ResNet Input Size](https://discuss.pytorch.org/t/torchvision-resnet-input-size/9405/3)\n",
    "\n",
    "[Transfer learning usage with different input size](https://discuss.pytorch.org/t/transfer-learning-usage-with-different-input-size/20744)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}