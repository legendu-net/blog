{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: Read/Write CSV in PySpark\n",
    "- Slug: pyspark-io-csv\n",
    "- Date: 2020-05-22 12:10:31\n",
    "- Category: Computer Science\n",
    "- Tags: programming, PySpark, CSV, text, IO\n",
    "- Author: Ben Du\n",
    "- Modified: 2020-05-22 12:10:31\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data in CSV Format\n",
    "\n",
    "1. `.load` is a general method for reading data in different format. \n",
    "    You have to specify the format of the data via the method `.format` of course.\n",
    "    `.csv` (both for CSV and TSV), `.json` and `.parquet` are specializations of `.load`. \n",
    "    `.format` is optional if you use a specific loading function (csv, json, etc.).\n",
    "\n",
    "2. No header by default.\n",
    "\n",
    "3. `.coalesece(1)` or `repartition(1)` if you want to write to only 1 file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "# A symbolic link of the Spark Home is made to /opt/spark for convenience\n",
    "findspark.init(\"/opt/spark\")\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName(\"PySpark\") \\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"denominator\", IntegerType(), False),\n",
    "        StructField(\"max_mod\", IntegerType(), False),\n",
    "        StructField(\"num_distinct\", IntegerType(), False),\n",
    "        StructField(\"max_dup\", IntegerType(), False),\n",
    "        StructField(\"avg_dup\", DoubleType(), False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------------+-------+-------+\n",
      "|denominator|max_mod|num_distinct|max_dup|avg_dup|\n",
      "+-----------+-------+------------+-------+-------+\n",
      "|       2014|      1|           1|    914|   14.0|\n",
      "|       2014|      1|           1|   1157|   -3.0|\n",
      "|       2014|      1|           1|   1902|    2.0|\n",
      "|       2014|      1|           1|    722|   -8.0|\n",
      "|       2014|      1|           1|   1347|    2.0|\n",
      "|       2014|      1|           1|   1824|    4.0|\n",
      "|       2014|      1|           1|   2133|   -2.0|\n",
      "|       2014|      1|           1|   1542|   -3.0|\n",
      "|       2014|      1|           1|   1509|   -1.0|\n",
      "|       2014|      1|           1|   1848|   -2.0|\n",
      "|       2014|      1|           1|   1655|   -5.0|\n",
      "|       2014|      1|           1|   1752|    7.0|\n",
      "|       2014|      1|           1|   1253|    3.0|\n",
      "|       2014|      1|           1|   1907|  142.0|\n",
      "|       2014|      1|           1|   1720|   -5.0|\n",
      "|       2014|      1|           1|   1733|   18.0|\n",
      "|       2014|      1|           1|   1640|   25.0|\n",
      "|       2014|      1|           1|   1714|   -1.0|\n",
      "|       2014|      1|           1|   1611|  191.0|\n",
      "|       2014|      1|           1|    553|   -7.0|\n",
      "+-----------+-------+------------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight = spark.read.format(\"csv\").option(\n",
    "    \"header\", \"true\"\n",
    ").schema(schema).load(\"../../home/media/data/flights14.csv\")\n",
    "flight.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------------+-------+-------+\n",
      "|denominator|max_mod|num_distinct|max_dup|avg_dup|\n",
      "+-----------+-------+------------+-------+-------+\n",
      "|       2014|      1|           1|    914|   14.0|\n",
      "|       2014|      1|           1|   1157|   -3.0|\n",
      "|       2014|      1|           1|   1902|    2.0|\n",
      "|       2014|      1|           1|    722|   -8.0|\n",
      "|       2014|      1|           1|   1347|    2.0|\n",
      "|       2014|      1|           1|   1824|    4.0|\n",
      "|       2014|      1|           1|   2133|   -2.0|\n",
      "|       2014|      1|           1|   1542|   -3.0|\n",
      "|       2014|      1|           1|   1509|   -1.0|\n",
      "|       2014|      1|           1|   1848|   -2.0|\n",
      "|       2014|      1|           1|   1655|   -5.0|\n",
      "|       2014|      1|           1|   1752|    7.0|\n",
      "|       2014|      1|           1|   1253|    3.0|\n",
      "|       2014|      1|           1|   1907|  142.0|\n",
      "|       2014|      1|           1|   1720|   -5.0|\n",
      "|       2014|      1|           1|   1733|   18.0|\n",
      "|       2014|      1|           1|   1640|   25.0|\n",
      "|       2014|      1|           1|   1714|   -1.0|\n",
      "|       2014|      1|           1|   1611|  191.0|\n",
      "|       2014|      1|           1|    553|   -7.0|\n",
      "+-----------+-------+------------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight = spark.read.option(\"header\", \"true\"\n",
    "                          ).schema(schema).csv(\"../../home/media/data/flights14.csv\")\n",
    "flight.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output with a Single Header\n",
    "\n",
    "https://stackoverflow.com/questions/38056152/merge-spark-output-csv-files-with-a-single-header\n",
    "\n",
    "https://stackoverflow.com/questions/36026070/building-a-structtype-from-a-dataframe-in-pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}