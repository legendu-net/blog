{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: Broadcast Join in Spark\n",
    "- Slug: pyspark-broadcast-join\n",
    "- Date: 2020-06-18 08:43:44\n",
    "- Category: Computer Science\n",
    "- Tags: programming, Python, HPC, high performance computing, PySpark, DataFrame, broadcast, join\n",
    "- Author: Ben Du\n",
    "- Modified: 2020-06-18 08:43:44\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips and Traps\n",
    "\n",
    "1. BroadcastHashJoin, i.e., map-side join is fast. \n",
    "    Use BroadcastHashJoin if possible. \n",
    "    Notice that Spark will automatically use BroacastHashJoin \n",
    "    if a table in inner join has a size less then the configured BroadcastHashJoin limit.\n",
    "    \n",
    "2. Notice that BroadcastJoin only works for inner joins. \n",
    "    If you have a outer join,\n",
    "    BroadcastJoin won't happend even if you explicitly Broadcast a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark-3.0.0-bin-hadoop3.2/\")\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType\n",
    "spark = SparkSession.builder.appName(\"PySpark_Union\") \\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name| id|\n",
      "+----+---+\n",
      "| Ben|  2|\n",
      "| Dan|  4|\n",
      "|Will|  1|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.createDataFrame(\n",
    "    pd.DataFrame(data=[\n",
    "        [\"Ben\", 2],\n",
    "        [\"Dan\", 4],\n",
    "        [\"Will\", 1],\n",
    "    ], columns=[\"name\", \"id\"])\n",
    ")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "| Ben| 30|\n",
      "| Dan| 25|\n",
      "|Will| 26|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        data=[\n",
    "            [\"Ben\", 30],\n",
    "            [\"Dan\", 25],\n",
    "            [\"Will\", 26],\n",
    "        ], columns=[\"name\", \"age\"]\n",
    "    )\n",
    ")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [name#25, id#26L, age#39L]\n",
      "+- *(5) SortMergeJoin [name#25], [name#38], Inner\n",
      "   :- *(2) Sort [name#25 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(name#25, 200), true, [id=#81]\n",
      "   :     +- *(1) Filter isnotnull(name#25)\n",
      "   :        +- *(1) Scan ExistingRDD[name#25,id#26L]\n",
      "   +- *(4) Sort [name#38 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(name#38, 200), true, [id=#87]\n",
      "         +- *(3) Filter isnotnull(name#38)\n",
      "            +- *(3) Scan ExistingRDD[name#38,age#39L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, [\"name\"]).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `BroadcastHashJoin` is used in the following execution plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Project [name#25, id#26L, age#39L]\n",
      "+- *(2) BroadcastHashJoin [name#25], [name#38], Inner, BuildRight\n",
      "   :- *(2) Filter isnotnull(name#25)\n",
      "   :  +- *(2) Scan ExistingRDD[name#25,id#26L]\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false])), [id=#122]\n",
      "      +- *(1) Filter isnotnull(name#38)\n",
      "         +- *(1) Scan ExistingRDD[name#38,age#39L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(broadcast(df2), [\"name\"]).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `BroadcastHashJoin` cannot be used for outer joins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [name#38, id#26L, age#39L]\n",
      "+- SortMergeJoin [name#25], [name#38], RightOuter\n",
      "   :- *(2) Sort [name#25 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(name#25, 200), true, [id=#154]\n",
      "   :     +- *(1) Filter isnotnull(name#25)\n",
      "   :        +- *(1) Scan ExistingRDD[name#25,id#26L]\n",
      "   +- *(4) Sort [name#38 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(name#38, 200), true, [id=#159]\n",
      "         +- *(3) Scan ExistingRDD[name#38,age#39L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(broadcast(df2), [\"name\"], \"right_outer\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}