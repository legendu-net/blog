{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Ben Du\n",
    "- Date: 2020-06-17 22:48:25\n",
    "- Title: Spark Configuration\n",
    "- Slug: spark-configuration\n",
    "- Category: Computer Science\n",
    "- Tags: Computer Science, Spark, configuration, big data, config\n",
    "- Modified: 2020-11-17 22:48:25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark-3.0.1-bin-hadoop3.2/\")\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType\n",
    "spark = SparkSession.builder.appName(\"Spark_Configuration\") \\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sparkConf from a SparkSession Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7fd375ce7520>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = spark.sparkContext.getConf()\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.port', '40851'),\n",
       " ('spark.sql.warehouse.dir', '/opt/spark-3.0.1-bin-hadoop3.2/warehouse'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '-Dderby.system.home=/opt/spark-3.0.1-bin-hadoop3.2/metastore_db'),\n",
       " ('spark.app.name', 'Spark_Configuration'),\n",
       " ('spark.app.id', 'local-1604190737869'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.host', 'ws-cb963871-b2cd-4e16-b4f8-a606431f8ba4'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.app.id=local-1604190737869\n",
      "spark.app.name=Spark_Configuration\n",
      "spark.driver.extraJavaOptions=-Dderby.system.home=/opt/spark-3.0.1-bin-hadoop3.2/metastore_db\n",
      "spark.driver.host=ws-cb963871-b2cd-4e16-b4f8-a606431f8ba4\n",
      "spark.driver.port=40851\n",
      "spark.executor.id=driver\n",
      "spark.master=local[*]\n",
      "spark.rdd.compress=True\n",
      "spark.serializer.objectStreamReset=100\n",
      "spark.sql.catalogImplementation=hive\n",
      "spark.sql.warehouse.dir=/opt/spark-3.0.1-bin-hadoop3.2/warehouse\n",
      "spark.submit.deployMode=client\n",
      "spark.submit.pyFiles=\n",
      "spark.ui.showConsoleProgress=true\n"
     ]
    }
   ],
   "source": [
    "print(conf.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.get(\"spark.yarn.appMasterEnv.ARROW_PRE_0_15_IPC_FORMAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.get(\"spark.executorEnv.ARROW_PRE_0_15_IPC_FORMAT\")"
   ]
  },
  {
   "source": [
    "## -XX:MaxDirectMemorySize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "--conf spark.executor.extraJavaOptions=-XX:MaxDirectMemorySize=8G"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkConf.set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkConf.setAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSession vs SparkContext vs SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkConf.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkContext.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}