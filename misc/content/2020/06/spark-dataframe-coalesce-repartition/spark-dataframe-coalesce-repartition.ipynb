{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Ben Du\n",
    "- Date: 2020-06-24 13:25:39\n",
    "- Title: Coalesce and Repartition in Spark DataFrame\n",
    "- Slug: spark-dataframe-coalesce-repartition\n",
    "- Category: Computer Science\n",
    "- Tags: programming, Scala, Spark, DataFrame, repartition, coalesce\n",
    "- Modified: 2022-01-18 14:34:12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://stackoverflow.com/questions/42171499/get-current-number-of-partitions-of-a-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coalesce vs repartition\n",
    "\n",
    "https://hackernoon.com/managing-spark-partitions-with-coalesce-and-repartition-4050c57ad5c4m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.error": {
       "message": "INVALID mime type: method. Must be in the format \"type/subtype[;optionalparameter]\"",
       "name": "Error",
       "stack": "Error: INVALID mime type: method. Must be in the format \"type/subtype[;optionalparameter]\"\n    at new mt (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:86:56282)\n    at Function.text (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:86:56933)\n    at s (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:143116)\n    at f (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:143827)\n    at h (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:144577)\n    at Array.map (<anonymous>)\n    at /usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:145763\n    at /usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:146005\n    at /usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:146012\n    at Array.map (<anonymous>)\n    at e.jupyterNotebookModelToNotebookData (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:145321)\n    at e.NotebookSerializer.deserializeNotebook (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:147518)\n    at I.$dataToNotebook (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:95:140362)\n    at t._doInvokeHandler (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:13802)\n    at t._invokeHandler (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:13486)\n    at t._receiveRequest (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:12097)\n    at t._receiveOneMessage (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:11025)\n    at /usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:8922\n    at u.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:66:1712)\n    at r.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:18942)\n    at /usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:114:34341\n    at u.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:66:1712)\n    at r.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:18942)\n    at n._receiveMessage (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:23523)\n    at /usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:21057\n    at u.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:66:1712)\n    at w.acceptChunk (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:15770)\n    at /usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:14900\n    at Socket.T (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:114:13813)\n    at Socket.emit (events.js:315:20)\n    at addChunk (internal/streams/readable.js:309:12)\n    at readableAddChunk (internal/streams/readable.js:284:9)\n    at Socket.Readable.push (internal/streams/readable.js:223:10)\n    at Pipe.onStreamRead (internal/stream_base_commons.js:188:23)"
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.code.notebook.error": {
       "message": "INVALID mime type: method. Must be in the format \"type/subtype[;optionalparameter]\"",
       "name": "Error",
       "stack": "Error: INVALID mime type: method. Must be in the format \"type/subtype[;optionalparameter]\"\n    at new mt (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:86:56282)\n    at Function.text (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:86:56933)\n    at s (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:143116)\n    at f (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:143827)\n    at h (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:144577)\n    at Array.map (<anonymous>)\n    at /usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:145763\n    at /usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:146005\n    at /usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:146012\n    at Array.map (<anonymous>)\n    at e.jupyterNotebookModelToNotebookData (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:145321)\n    at e.NotebookSerializer.deserializeNotebook (/usr/share/code/resources/app/extensions/ipynb/dist/ipynbMain.js:1:147518)\n    at I.$dataToNotebook (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:95:140362)\n    at t._doInvokeHandler (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:13802)\n    at t._invokeHandler (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:13486)\n    at t._receiveRequest (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:12097)\n    at t._receiveOneMessage (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:11025)\n    at /usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:99:8922\n    at u.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:66:1712)\n    at r.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:18942)\n    at /usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:114:34341\n    at u.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:66:1712)\n    at r.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:18942)\n    at n._receiveMessage (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:23523)\n    at /usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:21057\n    at u.fire (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:66:1712)\n    at w.acceptChunk (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:15770)\n    at /usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:74:14900\n    at Socket.T (/usr/share/code/resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:114:13813)\n    at Socket.emit (events.js:315:20)\n    at addChunk (internal/streams/readable.js:309:12)\n    at readableAddChunk (internal/streams/readable.js:284:9)\n    at Socket.Readable.push (internal/streams/readable.js:223:10)\n    at Pipe.onStreamRead (internal/stream_base_commons.js:188:23)"
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca765ad-0a94-43aa-834a-528b75c55be3",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.apache.spark spark-core_2.11 2.3.1\n",
    "org.apache.spark spark-sql_2.11 2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession$implicits$@60ad5f12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "    .master(\"local[2]\")\n",
    "    .appName(\"Spark Column Example\")\n",
    "    .config(\"spark.some.config.option\", \"some-value\")\n",
    "    .getOrCreate()\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.json(\"../../data/people.json\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Number of Partitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[age: bigint, name: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Control Number of Partitions of a DataFrame in Spark](http://www.legendu.net/en/blog/control-number-of-partitions-of-a-dataframe-in-spark/)\n",
    "\n",
    "- [Partition and Bucketing in Spark](http://www.legendu.net/misc/blog/partition-bucketing-in-spark/)\n",
    "\n",
    "- https://stackoverflow.com/questions/30995699/how-to-define-partitioning-of-dataframe\n",
    "\n",
    "- https://stackoverflow.com/questions/23127329/how-to-define-custom-partitioner-for-spark-rdds-of-equally-sized-partition-where\n",
    "\n",
    "- https://issues.apache.org/jira/browse/SPARK-22614\n",
    "\n",
    "- https://mungingdata.com/apache-spark/partitionby/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}