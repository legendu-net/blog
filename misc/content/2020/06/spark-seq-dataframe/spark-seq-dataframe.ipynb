{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Ben Du\n",
    "- Date: 2020-06-17\n",
    "- Title: Construct Simple Spark DataFrames Using Seq\n",
    "- Slug: spark-seq-dataframe\n",
    "- Category: Computer Science\n",
    "- Tags: programming, Scala, Spark, DataFrame, Seq, Construct\n",
    "- Modified: 2020-06-17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@mrpowers/manually-creating-spark-dataframes-b14dae906393"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq.toDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toDF() provides a concise syntax for creating DataFrames and can be accessed after importing Spark implicits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import spark.implicits._\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSession.createDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c65fcc5-65fc-41da-89de-7635d5fedf55",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.apache.spark spark-core_2.11 2.1.1\n",
    "org.apache.spark spark-sql_2.11 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession$implicits$@2d2d2d87"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{SparkSession, Row}\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"createDF example\")\n",
    "    .config(\"spark.some.config.option\", \"some-value\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Number: int, Words: string]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val someDF = Seq(\n",
    "  (8, \"bat\"),\n",
    "  (64, \"mouse\"),\n",
    "  (-27, \"horse\")\n",
    ").toDF(\"Number\", \"Words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Number|Words|\n",
      "+------+-----+\n",
      "|     8|  bat|\n",
      "|    64|mouse|\n",
      "|   -27|horse|\n",
      "+------+-----+\n",
      "\n",
      "root\n",
      " |-- Number: integer (nullable = false)\n",
      " |-- Words: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someDF.show()\n",
    "someDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[number: int, word: string]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val someData = Seq(\n",
    "  Row(8, \"bat\"),\n",
    "  Row(64, \"mouse\"),\n",
    "  Row(-27, \"horse\")\n",
    ")\n",
    "\n",
    "val someSchema = List(\n",
    "  StructField(\"number\", IntegerType, true),\n",
    "  StructField(\"word\", StringType, true)\n",
    ")\n",
    "\n",
    "val someDF = spark.createDataFrame(\n",
    "  spark.sparkContext.parallelize(someData),\n",
    "  StructType(someSchema)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq(1, 2, 3).toDF.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "createDF() is defined in spark-daria and allows for the following terse syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "input is incomplete",
     "evalue": "input is incomplete",
     "output_type": "error",
     "text": "input is incomplete",
     "traceback": [
      "\u001b[1;31minput is incomplete\u001b[0;0m"
     ]
    }
   ],
   "source": [
    "\n",
    "// val someDF = spark.createDF(\n",
    "//   List(\n",
    "//     (8, \"bat\"),\n",
    "//     (64, \"mouse\"),\n",
    "//     (-27, \"horse\")\n",
    "//   ), List(\n",
    "//     (\"number\", IntegerType, true),\n",
    "//     (\"word\", StringType, true)\n",
    "//   )\n",
    "// )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}