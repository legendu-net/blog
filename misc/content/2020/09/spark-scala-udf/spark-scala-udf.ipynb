{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: UDF in Spark\n",
    "- Slug: spark-scala-udf\n",
    "- Date: 2020-09-05 15:57:16\n",
    "- Category: Computer Science\n",
    "- Tags: programming, Scala, Spark, UDF, user-defined function\n",
    "- Author: Ben Du\n",
    "- Modified: 2020-09-05 15:57:16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "Use the higher-level standard Column-based functions with Dataset operators \n",
    "whenever possible before reverting to using your own custom UDF functions \n",
    "since UDFs are a blackbox for Spark and so it does not even try to optimize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(\"org.apache.spark\" %% \"spark-core\" % \"3.0.0\")\n",
    "interp.load.ivy(\"org.apache.spark\" %% \"spark-sql\" % \"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/09/07 11:51:53 WARN SparkSession$Builder: Using an existing SparkSession; some spark core configurations may not take effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@72b56dce\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    "    .builder()\n",
    "    .master(\"local[2]\")\n",
    "    .appName(\"Spark UDF Examples\")\n",
    "    .getOrCreate()\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/09/07 11:43:35 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/workdir/archives/blog/misc/content/spark-warehouse/').\n",
      "20/09/07 11:43:35 INFO SharedState: Warehouse path is 'file:/workdir/archives/blog/misc/content/spark-warehouse/'.\n",
      "20/09/07 11:43:37 INFO CodeGenerator: Code generated in 405.037 ms\n",
      "20/09/07 11:43:38 INFO CodeGenerator: Code generated in 17.1985 ms\n",
      "20/09/07 11:43:38 INFO CodeGenerator: Code generated in 23.8635 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| text|\n",
      "+---+-----+\n",
      "|  0|hello|\n",
      "|  1|world|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [id: int, text: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = Seq(\n",
    "    (0, \"hello\"), \n",
    "    (1, \"world\")\n",
    ").toDF(\"id\", \"text\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,StringType,Some(List(StringType)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.udf\n",
    "\n",
    "val upper: String => String = _.toUpperCase\n",
    "val upperUDF = udf(upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| id| text|upper|\n",
      "+---+-----+-----+\n",
      "|  0|hello|HELLO|\n",
      "|  1|world|WORLD|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"upper\", upperUDF($\"text\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function2>,LongType,Some(List(LongType, LongType)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val someUDF = udf((arg1: Long, arg2: Long) => {\n",
    "    arg1 + arg2\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map vs UDF\n",
    "\n",
    "https://stackoverflow.com/questions/38860808/performance-impact-of-rdd-api-vs-udfs-mixed-with-dataframe-api\n",
    "\n",
    "https://stackoverflow.com/questions/39039081/difference-between-a-map-and-udf\n",
    "\n",
    "https://stackoverflow.com/questions/43411234/spark-sql-whether-to-use-row-transformation-or-udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/Dataset.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/functions.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/Row.html\n",
    "\n",
    "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-udfs.html\n",
    "\n",
    "https://blog.cloudera.com/blog/2017/02/working-with-udfs-in-apache-spark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}