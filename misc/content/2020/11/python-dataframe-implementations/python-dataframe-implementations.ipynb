{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Ben Du\n",
    "- Date: 2020-11-26 14:24:00\n",
    "- Title: DataFrame Implementations in Python\n",
    "- Slug: scaling-pandas\n",
    "- Category: Computer Science\n",
    "- Tags: Computer Science, programming, Python, DataFrame, pandas, PySpark, Vaex, Modin, Dask, RAPIDS, cudf, cylon, big data\n",
    "- Modified: 2021-04-26 14:24:00\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** Things on this page are fragmentary and immature notes/thoughts of the author. Please read with your own judgement! **  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips and Traps\n",
    "\n",
    "There are multiple ways to handle big data in Python,\n",
    "among which \n",
    "[vaex](https://github.com/vaexio/vaex)\n",
    "and PySpark are the most popular ones.\n",
    "Dask is NOT a good option compared to vaex and PySpark.\n",
    "\n",
    "1. If you have relative large memory, \n",
    "    say more than 20G, \n",
    "    on your (single) machine, \n",
    "    you can handle (filtering, sorting, merging, etc.) \n",
    "    millions (magnitude of 1E6) of rows in pandas DataFrame without any pressure. \n",
    "    When you have more than 10 millions rows \n",
    "    or the memory on your (single) machine is restricted,\n",
    "    you should consider using big data tools such as \n",
    "    [vaex](https://github.com/vaexio/vaex)\n",
    "    and PySpark.\n",
    "\n",
    "4. Do NOT use the Jupyter/Lab plugin `jupyterlab-lsp` \n",
    "    if you work on big data in Jupyter/Lab.\n",
    "    The plugin `jupyterlab-lsp` has issues with large DataFrames \n",
    "    (both with pandas and PySpark DataFrames)\n",
    "    and can easily crash your Jupyter/Lab server \n",
    "    even if you have enough memory.\n",
    "\n",
    "\n",
    "[Benchmarking Python Distributed AI Backends with Wordbatch](https://towardsdatascience.com/benchmarking-python-distributed-ai-backends-with-wordbatch-9872457b785c)\n",
    "has a detailed comparison among Dask, Ray and PySpark.\n",
    "Dask is no good. \n",
    "Both Ray and PySpark scale well \n",
    "with Ray has slight performance advantge over PySpark.\n",
    "Also, Ray is easy to configure to Spark.\n",
    "Notice that [modin](https://github.com/modin-project/modin)\n",
    "is a project aiming at scaling pandas workflows by changing one line of code\n",
    "and it is based on Apache Ray.\n",
    "It will probably provide better performance than Dask if you work with data frames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [pandas DataFrame](https://github.com/pandas-dev/pandas)\n",
    "\n",
    "Pandas DataFrame is the most popular DataFrame implementation that people use Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [vaex](https://github.com/vaexio/vaex)\n",
    "\n",
    "**Vaex is currently the best alternative DataFrame implementation to pandas DataFrame.**\n",
    "\n",
    "\n",
    "Vaex is a high performance Python library for lazy Out-of-Core DataFrames (similar to Pandas), \n",
    "to visualize and explore big tabular datasets. \n",
    "It calculates statistics such as mean, sum, count, standard deviation etc, \n",
    "on an N-dimensional grid for more than a billion (10^9) samples/rows per second. \n",
    "Visualization is done using histograms, density plots and 3d volume rendering, \n",
    "allowing interactive exploration of big data. \n",
    "Vaex uses memory mapping, zero memory copy policy and lazy computations for best performance (no memory wasted).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [cylon](https://github.com/cylondata/cylon)\n",
    "\n",
    "Cylon use similar technologies (C++, Apache Arrow, etc.) as vaex.\n",
    "However,\n",
    "it doesn't seems to be as mature as vaex. \n",
    "A few advantages of Cylon compared to vaex are\n",
    "- cylon supports different langauge APIs (C++, Python, Java, etc)\n",
    "- cylon is distributed while vaex is single machine only\n",
    " \n",
    "Cylon is a fast, scalable distributed memory data parallel library for processing structured data. \n",
    "Cylon implements a set of relational operators to process data. \n",
    "While \"Core Cylon\" is implemented using system level C/C++, \n",
    "multiple language interfaces (Python and Java ) are provided to seamlessly integrate with existing applications, \n",
    "enabling both data and AI/ML engineers to invoke data processing operators in a familiar programming language. \n",
    "By default it works with MPI for distributing the applications.\n",
    "Internally Cylon uses Apache Arrow to represent the data in a column format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [polars](https://github.com/pola-rs/polars)\n",
    "\n",
    "Polars is a blazingly fast DataFrames library implemented in Rust using Apache Arrow as memory model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark DataFrame\n",
    "\n",
    "PySpark DataFrame is another good option (besides vaex) if you have to work on relatively large data on a single machine,\n",
    "especially if you have some Spark knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [cudf](https://github.com/rapidsai/cudf)\n",
    "\n",
    "cudf (developed by RAPIDS) is built based on the Apache Arrow columnar memory format, \n",
    "cuDF is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data.\n",
    "cuDF provides a pandas-like API that will be familiar to data engineers & data scientists, \n",
    "so they can use it to easily accelerate their workflows without going into the details of CUDA programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modin\n",
    "\n",
    "Modin, with Ray as a backend. By installing these, you might see significant benefit by changing just a single line (`import pandas as pd` to `import modin.pandas as pd`). Unlike the other tools, Modin aims to reach full compatibility with Pandas.\n",
    "\n",
    "Modin: a drop-in replacement for Pandas, powered by either Dask or Ray.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [dask.DataFrame](https://github.com/dask/dask)\n",
    "\n",
    "`dask.DataFrame` is not as good as other DataFrame implementations presented here. \n",
    "I'd suggest you try other alternatives (vaex or PySpark DataFrame).\n",
    "\n",
    "Dask is a low-level scheduler and a high-level partial Pandas replacement, \n",
    "geared toward running code on compute clusters.\n",
    "Dask provides `dask.dataframe`,\n",
    "a higher-level, Pandas-like library that can help you deal with out-of-core datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "1. compare PySpark DataFrame vs Vaex on a single machine ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Beyond Pandas: Spark, Dask, Vaex and other big data technologies battling head to head](https://towardsdatascience.com/beyond-pandas-spark-dask-vaex-and-other-big-data-technologies-battling-head-to-head-a453a1f8cc13)\n",
    "\n",
    "- [7 reasons why I love Vaex for data science](https://towardsdatascience.com/7-reasons-why-i-love-vaex-for-data-science-99008bc8044b)\n",
    "\n",
    "- [Vaex: Out of Core Dataframes for Python and Fast Visualization](https://towardsdatascience.com/vaex-out-of-core-dataframes-for-python-and-fast-visualization-12c102db044a)\n",
    "\n",
    "- [ML impossible: Train 1 billion samples in 5 minutes on your laptop using Vaex and Scikit-Learn](https://towardsdatascience.com/ml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f3850\n",
    "\n",
    "- [Scaling Pandas: Comparing Dask, Ray, Modin, Vaex, and RAPIDS](https://www.datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray#:~:text=Vaex,-Dask%20(Dataframe)%20is&text=Ultimately%2C%20Dask%20is%20more%20focused,on%20data%20processing%20and%20wrangling.)\n",
    "\n",
    "- [RIP Pandas 2.0: Time For DASK After VAEX !!!](https://towardsdatascience.com/dask-vs-vaex-for-big-data-38cb66728747)\n",
    "\n",
    "- [High performance Computing in Python](http://www.legendu.net/misc/blog/high-performance-computing-in-python)\n",
    "\n",
    "- [Hands on the Python Module dask](http://www.legendu.net/misc/blog/hands-on-the-python-module-dask/)\n",
    "\n",
    "- http://www.legendu.net/misc/blog/tips-on-pyspark/\n",
    "\n",
    "- http://www.legendu.net/misc/blog/pyspark-optimus-data-profiling/\n",
    "\n",
    "- https://www.dataquest.io/blog/pandas-big-data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}