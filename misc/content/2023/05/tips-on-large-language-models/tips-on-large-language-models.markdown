Status: published
Date: 2023-05-06 13:28:33
Modified: 2023-05-06 13:28:33
Author: Benjamin Du
Slug: tips-on-large-language-models
Title: Tips on Large Language Models
Category: Computer Science
Tags: Computer Science, programming, AI, machine learning, LLM, large language model, Bard, ChatGPT

**Things on this page are fragmentary and immature notes/thoughts of the author. Please read with your own judgement!**

- [AI Playground - Collection of LLMs](https://play.vercel.ai)

- [Google Bard](https://bard.google.com/)

- [ChatGPT](https://chat.openai.com/)

https://github.com/jmorganca/ollama
Get up and running with large language models locally

https://github.com/OpenBMB/ToolBench
ðŸ”¨This project (ToolLLM) aims to construct open-source, large-scale, high-quality instruction tuning SFT data to facilitate the construction of powerful LLMs with general tool-use capability. We aim to empower open-source LLMs to master thousands of diverse real-world APIs. We achieve this by collecting a high-quality instruction-tuning dataset. It is constructed automatically using the latest ChatGPT (gpt-3.5-turbo-16k), which is upgraded with enhanced function call capabilities. We provide the dataset, the corresponding training and evaluation scripts, and a capable model ToolLLaMA fine-tuned on ToolBench.



## References

- [LLM in Rust]( https://www.legendu.net/misc/blog/llm-in-rust ) 